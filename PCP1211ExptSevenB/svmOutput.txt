> library(caret)
> heart_df <- read.csv("/home/subalakshmi/PCP1211DALab/PCP1211ExptSevenB/heart_tidy.csv", 
+ sep = ",", header = FALSE)
> str(heart_df)
'data.frame':	300 obs. of  14 variables:
 $ V1 : int  63 67 67 37 41 56 62 57 63 53 ...
 $ V2 : int  1 1 1 1 0 1 0 0 1 1 ...
 $ V3 : int  1 4 4 3 2 2 4 4 4 4 ...
 $ V4 : int  145 160 120 130 130 120 140 120 130 140 ...
 $ V5 : int  233 286 229 250 204 236 268 354 254 203 ...
 $ V6 : int  1 0 0 0 0 0 0 0 0 1 ...
 $ V7 : int  2 2 2 0 2 0 2 0 2 2 ...
 $ V8 : int  150 108 129 187 172 178 160 163 147 155 ...
 $ V9 : int  0 1 1 0 0 0 0 1 0 1 ...
 $ V10: num  2.3 1.5 2.6 3.5 1.4 0.8 3.6 0.6 1.4 3.1 ...
 $ V11: int  3 2 2 3 1 1 3 1 2 3 ...
 $ V12: int  0 3 2 0 0 0 2 0 1 0 ...
 $ V13: int  6 3 7 3 3 3 3 3 7 7 ...
 $ V14: int  0 1 1 0 0 0 1 0 1 1 ...
> head(heart_df)
  V1 V2 V3  V4  V5 V6 V7  V8 V9 V10 V11 V12 V13 V14
1 63  1  1 145 233  1  2 150  0 2.3   3   0   6   0
2 67  1  4 160 286  0  2 108  1 1.5   2   3   3   1
3 67  1  4 120 229  0  2 129  1 2.6   2   2   7   1
4 37  1  3 130 250  0  0 187  0 3.5   3   0   3   0
5 41  0  2 130 204  0  2 172  0 1.4   1   0   3   0
6 56  1  2 120 236  0  0 178  0 0.8   1   0   3   0
> set.seed(3033)
> intrain <- createDataPartition(y = heart_df$V14, p = 0.7, list = FALSE)
> training <- heart_df[intrain, ]
> testing <- heart_df[-intrain, ]
> dim(training)
[1] 210  14
> dim(testing)
[1] 90 14
> anyNA(heart_df)
[1] FALSE
> summary(heart_df)
       V1              V2             V3              V4              V5       
 Min.   :29.00   Min.   :0.00   Min.   :1.000   Min.   : 94.0   Min.   :126.0  
 1st Qu.:48.00   1st Qu.:0.00   1st Qu.:3.000   1st Qu.:120.0   1st Qu.:211.0  
 Median :56.00   Median :1.00   Median :3.000   Median :130.0   Median :241.5  
 Mean   :54.48   Mean   :0.68   Mean   :3.153   Mean   :131.6   Mean   :246.9  
 3rd Qu.:61.00   3rd Qu.:1.00   3rd Qu.:4.000   3rd Qu.:140.0   3rd Qu.:275.2  
 Max.   :77.00   Max.   :1.00   Max.   :4.000   Max.   :200.0   Max.   :564.0  
       V6               V7               V8              V9              V10      
 Min.   :0.0000   Min.   :0.0000   Min.   : 71.0   Min.   :0.0000   Min.   :0.00  
 1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:133.8   1st Qu.:0.0000   1st Qu.:0.00  
 Median :0.0000   Median :0.5000   Median :153.0   Median :0.0000   Median :0.80  
 Mean   :0.1467   Mean   :0.9867   Mean   :149.7   Mean   :0.3267   Mean   :1.05  
 3rd Qu.:0.0000   3rd Qu.:2.0000   3rd Qu.:166.0   3rd Qu.:1.0000   3rd Qu.:1.60  
 Max.   :1.0000   Max.   :2.0000   Max.   :202.0   Max.   :1.0000   Max.   :6.20  
      V11             V12            V13             V14      
 Min.   :1.000   Min.   :0.00   Min.   :3.000   Min.   :0.00  
 1st Qu.:1.000   1st Qu.:0.00   1st Qu.:3.000   1st Qu.:0.00  
 Median :2.000   Median :0.00   Median :3.000   Median :0.00  
 Mean   :1.603   Mean   :0.67   Mean   :4.727   Mean   :0.46  
 3rd Qu.:2.000   3rd Qu.:1.00   3rd Qu.:7.000   3rd Qu.:1.00  
 Max.   :3.000   Max.   :3.00   Max.   :7.000   Max.   :1.00  
> training[["V14"]] = factor(training[["V14"]])
> trctrl <- trainControl(method = "repeatedcv", number = 10, repeats = 3)
> set.seed(3233)
> svm_Linear <- train(V14 ~ ., data = training, method = "svmLinear", 
+ trControl = trctrl, preProcess = c("center", "scale"), tuneLength = 10)
> svm_Linear
Support Vector Machines with Linear Kernel 

210 samples
 13 predictor
  2 classes: '0', '1' 

Pre-processing: centered (13), scaled (13) 
Resampling: Cross-Validated (10 fold, repeated 3 times) 
Summary of sample sizes: 189, 189, 189, 189, 189, 189, ... 
Resampling results:

  Accuracy   Kappa   
  0.7920635  0.581696

Tuning parameter 'C' was held constant at a value of 1
> test_pred <- predict(svm_Linear, newdata = testing)
> str(test_pred)
 Factor w/ 2 levels "0","1": 1 2 2 2 1 1 2 1 1 2 ...
> confusionMatrix(factor(test_pred, levels = 1:148), factor(testing$V14, 
+ levels = 1:148))
Confusion Matrix and Statistics

Overall Statistics
                                     
               Accuracy : 1          
                 95% CI : (0.8942, 1)
    No Information Rate : 1          
    P-Value [Acc > NIR] : 1          
                                     
                  Kappa : NaN        
                                     
 Mcnemar's Test P-Value : NA         

> grid <- expand.grid(C = c(0, 0.01, 0.05, 0.1, 0.25, 0.5, 0.75, 
+ 1, 1.25, 1.5, 1.75, 2, 5))
> set.seed(3233)
> svm_Linear_Grid <- train(V14 ~ ., data = training, method = "svmLinear", 
+ trControl = trctrl, preProcess = c("center", "scale"), tuneGrid = grid, 
+ tuneLength = 10)
> plot(svm_Linear_Grid)
> test_pred_grid <- predict(svm_Linear_Grid, newdata = testing)
> test_pred_grid
 [1] 0 1 1 1 0 0 1 0 0 1 0 1 0 1 1 1 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 1 1 1 1
[40] 1 0 0 1 0 0 1 0 1 1 1 1 0 1 1 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 1 0 1 1 0 0
[79] 0 1 0 1 1 0 1 0 0 0 1 0
Levels: 0 1
> confusionMatrix(factor(test_pred_grid, levels = 1:148), factor(testing$V14, 
+ levels = 1:148))
Confusion Matrix and Statistics

Overall Statistics
                                     
               Accuracy : 1          
                 95% CI : (0.8911, 1)
    No Information Rate : 1          
    P-Value [Acc > NIR] : 1          
                                     
                  Kappa : NaN        
                                     
 Mcnemar's Test P-Value : NA         

> set.seed(3233)
> svm_Radial <- train(V14 ~ ., data = training, method = "svmRadial", 
+ trControl = trctrl, preProcess = c("center", "scale"), tuneLength = 10)
> plot(svm_Radial)
> test_pred_Radial <- predict(svm_Radial, newdata = testing)
> confusionMatrix(factor(test_pred_Radial, levels = 1:148), factor(testing$V14, 
+ levels = 1:148))
Confusion Matrix and Statistics
Overall Statistics
                                     
               Accuracy : 1          
                 95% CI : (0.8911, 1)
    No Information Rate : 1          
    P-Value [Acc > NIR] : 1          
                                     
                  Kappa : NaN        
                                     
 Mcnemar's Test P-Value : NA         

> grid_radial <- expand.grid(sigma = c(0, 0.01, 0.02, 0.025, 0.03, 
+ 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1, 0.25, 0.5, 0.75, 
+ 0.9), C = c(0, 0.01, 0.05, 0.1, 0.25, 0.5, 0.75, 1, 1.5, 
+ 2, 5))
> set.seed(3233)
> svm_Radial_Grid <- train(V14 ~ ., data = training, method = "svmRadial", 
+ trControl = trctrl, preProcess = c("center", "scale"), tuneGrid = grid_radial, 
+ tuneLength = 10)
> svm_Radial_Grid
Support Vector Machines with Radial Basis Function Kernel 

210 samples
 13 predictor
  2 classes: '0', '1' 

Pre-processing: centered (13), scaled (13) 
Resampling: Cross-Validated (10 fold, repeated 3 times) 
Summary of sample sizes: 189, 189, 189, 189, 189, 189, ... 
Resampling results across tuning parameters:

  sigma  C     Accuracy   Kappa      
  0.000  0.00        NaN          NaN
  0.000  0.01  0.5238095  0.000000000
  0.000  0.05  0.5238095  0.000000000
  0.000  0.10  0.5238095  0.000000000
  0.000  0.25  0.5238095  0.000000000
  0.000  0.50  0.5238095  0.000000000
  0.900  0.75  0.5492063  0.055825807
  0.900  1.00  0.5444444  0.055132187
  0.900  1.50  0.5555556  0.081488190
  0.900  2.00  0.5555556  0.081488190
  0.900  5.00  0.5555556  0.081488190

Accuracy was used to select the optimal model using the largest value.
The final values used for the model were sigma = 0.02 and C = 0.25.
> plot(svm_Radial_Grid)
> test_pred_Radial_Grid <- predict(svm_Radial_Grid, newdata = testing)
> confusionMatrix(factor(test_pred_Radial_Grid, levels = 1:148), 
+ factor(testing$V14, levels = 1:148))
Confusion Matrix and Statistics

